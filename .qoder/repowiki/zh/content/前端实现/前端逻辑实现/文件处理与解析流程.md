# 文件处理与解析流程

<cite>
**本文档引用的文件**
- [main.js](file://src/main.js)
- [commands.rs](file://src-tauri/src/tauri/commands.rs)
- [log_parser.rs](file://src-tauri/src/parser/log_parser.rs)
- [file_reader.rs](file://src-tauri/src/parser/file_reader.rs)
- [parse_result.rs](file://src-tauri/src/models/parse_result.rs)
</cite>

## 目录
1. [文件处理主流程](#文件处理主流程)
2. [文件验证与读取](#文件验证与读取)
3. [大文件分块解析策略](#大文件分块解析策略)
4. [前后端解析接口契约](#前后端解析接口契约)

## 文件处理主流程

`handleFile` 方法是文件处理的核心入口，负责协调整个文件解析流程。该方法首先进行文件验证和大小检查，然后根据文件大小决定采用直接解析还是分块解析策略。

**Section sources**
- [main.js](file://src/main.js#L231-L298)

## 文件验证与读取

### 文件类型验证逻辑

`isValidFile` 方法通过检查文件扩展名来验证文件类型。该方法将文件名转换为小写后，检查是否以 `.log` 或 `.txt` 结尾，仅允许这两种格式的文件被处理。

```mermaid
flowchart TD
Start([开始验证]) --> ExtractName["提取文件名并转为小写"]
ExtractName --> CheckExtension{"是否以.log或.txt结尾?"}
CheckExtension --> |是| Valid["返回true"]
CheckExtension --> |否| Invalid["返回false"]
Valid --> End([验证通过])
Invalid --> End
```

**Diagram sources**
- [main.js](file://src/main.js#L300-L304)

### 异步文件读取实现

`readFileContent` 方法使用 `FileReader` API 实现异步文件读取。该方法返回一个 Promise，当文件读取完成时解析为文件内容字符串，采用 UTF-8 编码读取文本文件。

```mermaid
sequenceDiagram
participant Frontend as 前端应用
participant FileReader as FileReader
participant File as 文件对象
Frontend->>FileReader : 创建FileReader实例
Frontend->>FileReader : 设置onload事件处理器
Frontend->>FileReader : 设置onerror事件处理器
Frontend->>FileReader : 调用readAsText(File, 'UTF-8')
FileReader->>File : 读取文件内容
alt 读取成功
File->>FileReader : 返回文本内容
FileReader->>Frontend : 触发onload事件
Frontend->>Frontend : resolve(Promise)
else 读取失败
File->>FileReader : 返回错误
FileReader->>Frontend : 触发onerror事件
Frontend->>Frontend : reject(Promise)
end
```

**Diagram sources**
- [main.js](file://src/main.js#L306-L317)

## 大文件分块解析策略

当文件行数超过 1000 行且分块加载功能启用时，系统会调用 `parseLargeFile` 方法进行分块解析。该策略通过渐进式加载提高大文件处理的响应性能。

### 分块处理流程

```mermaid
flowchart TD
Start([开始分块处理]) --> CalculateChunkSize["计算最优块大小"]
CalculateChunkSize --> CalculateTotalChunks["计算总块数"]
CalculateTotalChunks --> InitializeArray["初始化结果数组"]
InitializeArray --> ProcessFirstChunk["处理第一块数据"]
ProcessFirstChunk --> ProcessRemaining["异步处理剩余块"]
ProcessRemaining --> StartInterval["启动定期检查间隔"]
StartInterval --> End([分块处理初始化完成])
subgraph "自适应块大小计算"
CalculateChunkSize --> |超大文件>10万行| SetSmallChunk["设置小块大小(50-200)"]
CalculateChunkSize --> |大文件>1万行| SetMediumChunk["设置中等块大小(100-500)"]
CalculateChunkSize --> |普通文件| SetDefaultChunk["设置默认块大小(100)"]
end
```

**Diagram sources**
- [main.js](file://src/main.js#L419-L440)

### 分块处理机制

分块处理采用渐进式加载策略，优先处理第一块数据以快速显示部分内容，然后在浏览器空闲时通过 `requestIdleCallback` 异步处理剩余块。同时启动定期检查机制，根据可视区域需求动态加载必要数据块。

```mermaid
sequenceDiagram
participant App as 应用程序
participant ChunkLoader as 分块加载器
participant VirtualScroll as 虚拟滚动
App->>ChunkLoader : parseLargeFile(lines)
ChunkLoader->>ChunkLoader : calculateOptimalChunkSize()
ChunkLoader->>ChunkLoader : 初始化currentEntries数组
ChunkLoader->>ChunkLoader : processChunk(lines, 0)
ChunkLoader->>App : renderResults()
ChunkLoader->>ChunkLoader : processRemainingChunks()
ChunkLoader->>window : requestIdleCallback(processNextChunk)
loop 浏览器空闲时
window->>ChunkLoader : 执行processNextChunk
ChunkLoader->>ChunkLoader : 处理下一个未加载的块
ChunkLoader->>VirtualScroll : 检查是否在可视区域内
alt 在可视区域内
VirtualScroll->>App : renderVisibleItems()
end
end
ChunkLoader->>ChunkLoader : startChunkCheckInterval()
loop 每500ms
ChunkLoader->>VirtualScroll : checkAndLoadRequiredChunks()
VirtualScroll->>ChunkLoader : 返回需要加载的块索引
ChunkLoader->>ChunkLoader : loadChunksAsync()
end
```

**Section sources**
- [main.js](file://src/main.js#L419-L440)

## 前后端解析接口契约

### 前后端调用流程

前端通过 Tauri 的 `invoke` 机制调用后端 `parse_file` 命令，实现跨进程通信。后端解析完成后将结果返回给前端进行渲染。

```mermaid
sequenceDiagram
participant Frontend as 前端应用
participant TauriBridge as Tauri 桥接
participant Backend as 后端解析器
Frontend->>Frontend : handleFile(file)
Frontend->>Frontend : isValidFile(file)
Frontend->>Frontend : readFileContent(file)
Frontend->>Frontend : split lines
alt 行数 > 1000
Frontend->>Frontend : parseLargeFile(lines)
else
Frontend->>Frontend : parseRealLogLines(lines)
end
Frontend->>TauriBridge : invoke('parse_file', request)
TauriBridge->>Backend : 调用parse_file命令
Backend->>Backend : validate_file_type()
Backend->>Backend : read_lines()
Backend->>Backend : parse_lines()
Backend->>Backend : merge_multiline_logs()
Backend->>Backend : render_entries()
Backend->>TauriBridge : 返回ParseFileResponse
TauriBridge->>Frontend : 解析结果
Frontend->>Frontend : renderResults()
```

**Diagram sources**
- [main.js](file://src/main.js#L231-L298)
- [commands.rs](file://src-tauri/src/tauri/commands.rs#L68-L121)

### 数据传递格式

前后端通过定义良好的数据结构进行通信，确保类型安全和数据完整性。

#### 请求格式
```mermaid
erDiagram
ParseFileRequest {
string file_path PK
string plugin_name FK
}
```

#### 响应格式
```mermaid
erDiagram
ParseFileResponse {
boolean success
ParseResultSet result_set FK
string error
}
ParseResultSet {
ParseResult[] results
TotalParseStats total_stats
ParseConfig config
}
ParseResult {
LogEntry original
RenderedBlock[] rendered_blocks
boolean is_error
boolean is_warning
ParseStats stats
}
TotalParseStats {
integer total_lines
integer success_lines
integer error_lines
integer warning_lines
integer total_blocks
integer total_parse_time_ms
float avg_parse_time_per_line_ms
}
ParseConfig {
string plugin_name
boolean enable_cache
integer max_file_size
integer timeout_ms
}
ParseFileResponse ||--o{ ParseResultSet : "包含"
ParseResultSet ||--o{ ParseResult : "包含"
ParseResultSet ||--o{ TotalParseStats : "包含"
ParseResultSet ||--o{ ParseConfig : "包含"
ParseResult ||--o{ LogEntry : "原始"
ParseResult ||--o{ RenderedBlock : "渲染块"
ParseResult ||--o{ ParseStats : "统计"
```

**Diagram sources**
- [commands.rs](file://src-tauri/src/tauri/commands.rs#L68-L121)
- [parse_result.rs](file://src-tauri/src/models/parse_result.rs#L1-L285)