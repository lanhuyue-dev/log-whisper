use axum::{
    extract::State,
    http::StatusCode,
    response::Json,
    routing::{get, post},
    Router,
};
use serde::{Deserialize, Serialize};
use tower_http::cors::CorsLayer;
use log::{info, error, warn};
use std::sync::Arc;
use std::env;
use std::fs;
use std::path::Path;

mod config;
mod plugins;
use config::{ConfigService, ThemeConfig, ThemeMode, ParseConfig, PluginConfig, WindowConfig, ConfigUpdateRequest};
use plugins::core::EnhancedPluginManager;
use plugins::LogEntry as PluginLogEntry;

#[derive(Debug, Serialize, Deserialize)]
struct AppConfig {
    port: u16,
    log_file: String,
    log_level: String,
}

impl Default for AppConfig {
    fn default() -> Self {
        Self {
            port: 3030,
            log_file: "logs/log-whisper.log".to_string(),
            log_level: "info".to_string(),
        }
    }
}

#[derive(Debug, Serialize, Deserialize)]
struct HealthResponse {
    status: String,
    version: String,
    timestamp: String,
}

#[derive(Debug, Serialize, Deserialize)]
struct ParseRequest {
    #[serde(default)]
    file_path: Option<String>,
    #[serde(default)]
    content: Option<String>,
    #[serde(default)]
    plugin: Option<String>,
    #[serde(default)]
    chunk_size: Option<usize>,
    #[serde(default)]
    chunk_index: Option<usize>,
}

#[derive(Debug, Serialize, Deserialize)]
struct ParseResponse {
    success: bool,
    entries: Vec<LogEntry>,
    stats: ParseStats,
    chunk_info: Option<ChunkInfo>,
    error: Option<String>,
    detected_format: Option<String>, // æ–°å¢ï¼šæ£€æµ‹åˆ°çš„æ—¥å¿—æ ¼å¼
}

#[derive(Debug, Serialize, Deserialize)]
struct ChunkInfo {
    total_chunks: usize,
    current_chunk: usize,
    has_more: bool,
}

#[derive(Debug, Serialize, Deserialize)]
struct LogEntry {
    line_number: usize,
    content: String,
    timestamp: Option<String>,
    level: Option<String>,
    formatted_content: Option<String>,
    metadata: std::collections::HashMap<String, String>,
    processed_by: Vec<String>,
}

#[derive(Debug, Serialize, Deserialize)]
struct ParseStats {
    total_lines: usize,
    success_lines: usize,
    error_lines: usize,
    parse_time_ms: u64,
}

#[derive(Debug, Serialize, Deserialize)]
struct Plugin {
    name: String,
    description: String,
    version: String,
}

#[derive(Debug, Serialize, Deserialize)]
struct PluginsResponse {
    plugins: Vec<Plugin>,
}

// é…ç½®ç›¸å…³ç»“æ„ä½“
#[derive(Debug, Serialize, Deserialize)]
struct ConfigResponse {
    success: bool,
    message: String,
    data: Option<serde_json::Value>,
}

#[derive(Debug, Serialize, Deserialize)]
struct ThemeResponse {
    mode: String,
    primary_color: String,
    accent_color: String,
    font_size: u32,
    font_family: String,
}

#[derive(Debug, Serialize, Deserialize)]
struct ThemeUpdateRequest {
    mode: String,
    primary_color: Option<String>,
    accent_color: Option<String>,
    font_size: Option<u32>,
    font_family: Option<String>,
}

// å¥åº·æ£€æŸ¥
async fn health_check() -> Json<HealthResponse> {
    Json(HealthResponse {
        status: "ok".to_string(),
        version: "1.0.0".to_string(),
        timestamp: chrono::Utc::now().to_rfc3339(),
    })
}

// è·å–å¯ç”¨æ’ä»¶
async fn get_plugins() -> Json<PluginsResponse> {
    let plugins = vec![
        Plugin {
            name: "auto".to_string(),
            description: "è‡ªåŠ¨æ£€æµ‹".to_string(),
            version: "1.0.0".to_string(),
        },
        Plugin {
            name: "mybatis".to_string(),
            description: "MyBatis SQL è§£æå™¨".to_string(),
            version: "1.0.0".to_string(),
        },
        Plugin {
            name: "docker_json".to_string(),
            description: "Docker JSON æ—¥å¿—".to_string(),
            version: "1.0.0".to_string(),
        },
        Plugin {
            name: "raw".to_string(),
            description: "åŸå§‹æ–‡æœ¬".to_string(),
            version: "1.0.0".to_string(),
        },
    ];
    
    Json(PluginsResponse { plugins })
}

// è§£ææ—¥å¿—
async fn parse_log(Json(request): Json<ParseRequest>) -> Result<Json<ParseResponse>, StatusCode> {
    let start_time = std::time::Instant::now();
    
    info!("æ”¶åˆ°è§£æè¯·æ±‚: {:?}", request);
    
    // ç¡®å®šå†…å®¹æ¥æº
    let content = if let Some(file_path) = &request.file_path {
        // æ–‡ä»¶è·¯å¾„æ¨¡å¼
        info!("ä½¿ç”¨æ–‡ä»¶è·¯å¾„æ¨¡å¼: {}", file_path);
        
        // æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if !std::path::Path::new(file_path).exists() {
            error!("æ–‡ä»¶ä¸å­˜åœ¨: {}", file_path);
            return Ok(Json(ParseResponse {
                success: false,
                entries: vec![],
                stats: ParseStats {
                    total_lines: 0,
                    success_lines: 0,
                    error_lines: 0,
                    parse_time_ms: 0,
                },
                chunk_info: None,
                error: Some(format!("æ–‡ä»¶ä¸å­˜åœ¨: {}", file_path)),
                detected_format: None,
            }));
        }
        
        // æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å¯è¯»
        if !std::path::Path::new(file_path).is_file() {
            error!("è·¯å¾„ä¸æ˜¯æ–‡ä»¶: {}", file_path);
            return Ok(Json(ParseResponse {
                success: false,
                entries: vec![],
                stats: ParseStats {
                    total_lines: 0,
                    success_lines: 0,
                    error_lines: 0,
                    parse_time_ms: 0,
                },
                chunk_info: None,
                error: Some(format!("è·¯å¾„ä¸æ˜¯æ–‡ä»¶: {}", file_path)),
                detected_format: None,
            }));
        }
        
        // è¯»å–æ–‡ä»¶å†…å®¹
        match std::fs::read_to_string(file_path) {
            Ok(content) => {
                info!("æ–‡ä»¶è¯»å–æˆåŠŸï¼Œå¤§å°: {} bytes", content.len());
                content
            },
            Err(e) => {
                error!("è¯»å–æ–‡ä»¶å¤±è´¥: {} - é”™è¯¯: {}", file_path, e);
                return Ok(Json(ParseResponse {
                    success: false,
                    entries: vec![],
                    stats: ParseStats {
                        total_lines: 0,
                        success_lines: 0,
                        error_lines: 0,
                        parse_time_ms: 0,
                    },
                    chunk_info: None,
                    error: Some(format!("è¯»å–æ–‡ä»¶å¤±è´¥: {} - é”™è¯¯: {}", file_path, e)),
                    detected_format: None,
                }));
            }
        }
    } else if let Some(content) = &request.content {
        // å†…å®¹ä¼ è¾“æ¨¡å¼
        info!("ä½¿ç”¨å†…å®¹ä¼ è¾“æ¨¡å¼ï¼Œå¤§å°: {} bytes", content.len());
        content.clone()
    } else {
        error!("è¯·æ±‚ä¸­æ—¢æ²¡æœ‰æ–‡ä»¶è·¯å¾„ä¹Ÿæ²¡æœ‰å†…å®¹");
        return Ok(Json(ParseResponse {
            success: false,
            entries: vec![],
            stats: ParseStats {
                total_lines: 0,
                success_lines: 0,
                error_lines: 0,
                parse_time_ms: 0,
            },
            chunk_info: None,
            error: Some("è¯·æ±‚ä¸­æ—¢æ²¡æœ‰æ–‡ä»¶è·¯å¾„ä¹Ÿæ²¡æœ‰å†…å®¹".to_string()),
            detected_format: None,
        }));
    };
    
    let lines: Vec<&str> = content.lines().filter(|line| !line.trim().is_empty()).collect();
    let total_lines = lines.len();
    
    // æ·»åŠ è¯¦ç»†çš„è¡Œè°ƒè¯•ä¿¡æ¯
    info!("è¿‡æ»¤åæœ‰æ•ˆè¡Œæ•°: {}", total_lines);
    for (i, line) in lines.iter().take(5).enumerate() {
        info!("è¡Œ {}: é•¿åº¦={}, å†…å®¹={}", i + 1, line.len(), line.chars().take(200).collect::<String>());
    }
    
    // æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†å—å¤„ç†
    let chunk_size = request.chunk_size.unwrap_or(1000); // é»˜è®¤1000è¡Œä¸€å—
    let chunk_index = request.chunk_index.unwrap_or(0);
    
    // åªæœ‰å½“æ–‡ä»¶å¤§å°è¶…è¿‡åˆ†å—å¤§å°ä¸”æ˜ç¡®è¯·æ±‚åˆ†å—æ—¶æ‰åˆ†å—å¤„ç†
    let should_chunk = total_lines > chunk_size && request.chunk_size.is_some();
    
    info!("åˆ†å—åˆ¤æ–­: total_lines={}, chunk_size={}, chunk_size_requested={}, should_chunk={}", 
         total_lines, chunk_size, request.chunk_size.is_some(), should_chunk);
    
    if should_chunk {
        // åˆ†å—å¤„ç† - ä½¿ç”¨æ’ä»¶ç³»ç»Ÿè¿›è¡Œå¿«é€Ÿå¤„ç†
        let start_index = chunk_index * chunk_size;
        let _end_index = std::cmp::min(start_index + chunk_size, total_lines);
        
        info!("ğŸ”§ åˆ†å—å¤„ç†ï¼šä½¿ç”¨æ’ä»¶ç³»ç»Ÿå¿«é€Ÿå¤„ç†å®¹å™¨JSONæ ¼å¼");
        
        // å°†åˆ†å—è¡Œè½¬æ¢ä¸ºLogEntry
        let chunk_entries: Vec<LogEntry> = lines.iter().enumerate().skip(start_index).take(chunk_size)
            .map(|(global_index, line)| LogEntry {
                line_number: global_index + 1,
                content: line.to_string(),
                timestamp: extract_timestamp(line),
                level: extract_log_level(line),
                formatted_content: Some(line.trim().to_string()),
                metadata: std::collections::HashMap::new(),
                processed_by: vec!["generic_parser".to_string()],
            })
            .collect();
        
        // ä½¿ç”¨æ’ä»¶ç³»ç»Ÿå¤„ç†åˆ†å—
        let processed_entries = match process_logs_with_plugin_system(&chunk_entries).await {
            Ok(entries) => entries,
            Err(e) => {
                error!("åˆ†å—æ’ä»¶ç³»ç»Ÿå¤„ç†å¤±è´¥: {}", e);
                // å›é€€åˆ°ä¼ ç»Ÿå¤„ç†
                chunk_entries
            }
        };
        
        let entries = processed_entries;
        
        let total_chunks = (total_lines + chunk_size - 1) / chunk_size; // å‘ä¸Šå–æ•´
        let has_more = chunk_index + 1 < total_chunks;
        
        let parse_time = start_time.elapsed().as_millis() as u64;
        
        let stats = ParseStats {
            total_lines,
            success_lines: entries.len(),
            error_lines: 0,
            parse_time_ms: parse_time,
        };
        
        let chunk_info = ChunkInfo {
            total_chunks,
            current_chunk: chunk_index,
            has_more,
        };
        
        info!("åˆ†å—è§£æå®Œæˆ: ç¬¬{}/{}å—ï¼Œ{}è¡Œï¼Œè€—æ—¶: {}ms", 
              chunk_index + 1, total_chunks, entries.len(), parse_time);
        
        Ok(Json(ParseResponse {
            success: true,
            entries,
            stats,
            chunk_info: Some(chunk_info),
            error: None,
            detected_format: None, // åˆ†å—å¤„ç†æ—¶ä¸åšæ ¼å¼æ£€æµ‹
        }))
    } else {
        // ä½¿ç”¨å¢å¼ºæ’ä»¶ç³»ç»Ÿå¤„ç†ï¼ˆå°æ–‡ä»¶ï¼‰
        info!("ä½¿ç”¨å¢å¼ºæ’ä»¶ç³»ç»Ÿå¤„ç†æ—¥å¿—");
        
        // å°†å­—ç¬¦ä¸²è¡Œè½¬æ¢ä¸ºLogEntry
        let log_entries: Vec<LogEntry> = lines.iter().enumerate()
            .map(|(index, line)| LogEntry {
                line_number: index + 1,
                content: line.to_string(),
                timestamp: extract_timestamp(line),
                level: extract_log_level(line),
                formatted_content: Some(line.trim().to_string()),
                metadata: std::collections::HashMap::new(),
                processed_by: vec!["generic_parser".to_string()],
            })
            .collect();
        
        // ä½¿ç”¨æ’ä»¶ç³»ç»Ÿå¤„ç†
        let processed_entries = match process_logs_with_plugin_system(&log_entries).await {
            Ok(entries) => entries,
            Err(e) => {
                error!("æ’ä»¶ç³»ç»Ÿå¤„ç†å¤±è´¥: {}", e);
                // å›é€€åˆ°ä¼ ç»Ÿå¤„ç†
                let mut fallback_entries = Vec::new();
                for (index, line) in lines.iter().enumerate() {
                    fallback_entries.push(LogEntry {
                        line_number: index + 1,
                        content: line.to_string(),
                        timestamp: extract_timestamp(line),
                        level: extract_log_level(line),
                        formatted_content: Some(line.trim().to_string()),
                        metadata: std::collections::HashMap::new(),
                        processed_by: vec!["generic_parser".to_string()],
                    });
                }
                return Ok(Json(ParseResponse {
                    success: true,
                    entries: fallback_entries,
                    stats: ParseStats {
                        total_lines: lines.len(),
                        success_lines: lines.len(),
                        error_lines: 0,
                        parse_time_ms: start_time.elapsed().as_millis() as u64,
                    },
                    chunk_info: None,
                    error: Some(format!("æ’ä»¶ç³»ç»Ÿå¤„ç†å¤±è´¥: {}", e)),
                    detected_format: None,
                }));
            }
        };
        
        // æ’ä»¶ç³»ç»Ÿå·²ç»è¿”å›LogEntryæ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
        let entries = processed_entries;
        
        let parse_time = start_time.elapsed().as_millis() as u64;
        
        let stats = ParseStats {
            total_lines: lines.len(),
            success_lines: entries.len(),
            error_lines: 0,
            parse_time_ms: parse_time,
        };
        
        // æ£€æµ‹æ—¥å¿—æ ¼å¼
        let detected_format = detect_log_format(&lines);
        
        info!("å…¨é‡è§£æå®Œæˆ: {} è¡Œï¼Œå¤„ç†ä¸º {} æ¡ç›®ï¼Œè€—æ—¶: {}msï¼Œæ£€æµ‹æ ¼å¼: {:?}", 
              lines.len(), entries.len(), parse_time, detected_format);
        
        Ok(Json(ParseResponse {
            success: true,
            entries,
            stats,
            chunk_info: None,
            error: None,
            detected_format: Some(detected_format),
        }))
    }
}

// å…¨å±€æ’ä»¶ç®¡ç†å™¨ç¼“å­˜
static mut PLUGIN_MANAGER: Option<Arc<EnhancedPluginManager>> = None;
static INITIALIZED: std::sync::atomic::AtomicBool = std::sync::atomic::AtomicBool::new(false);

// ä½¿ç”¨æ’ä»¶ç³»ç»Ÿå¤„ç†æ—¥å¿—
async fn process_logs_with_plugin_system(entries: &[LogEntry]) -> Result<Vec<LogEntry>, String> {
    info!("ğŸ”§ å¼€å§‹æ’ä»¶ç³»ç»Ÿå¤„ç†ï¼Œè¾“å…¥æ¡ç›®æ•°: {}", entries.len());
    
    // è¾“å‡ºå‰å‡ ä¸ªæ¡ç›®çš„å†…å®¹ç”¨äºè°ƒè¯•
    for (i, entry) in entries.iter().take(3).enumerate() {
        info!("ğŸ”§ è¾“å…¥æ¡ç›® {}: è¡Œå·={}, å†…å®¹å‰100å­—ç¬¦={}", 
              i + 1, entry.line_number, entry.content.chars().take(100).collect::<String>());
    }
    
    // ä½¿ç”¨å…¨å±€ç¼“å­˜çš„æ’ä»¶ç®¡ç†å™¨
    let plugin_manager = get_or_init_plugin_manager().await
        .map_err(|e| format!("æ’ä»¶ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {}", e))?;
    
    info!("ğŸ”§ ä½¿ç”¨ç¼“å­˜çš„æ’ä»¶ç³»ç»Ÿ");
    
    // è½¬æ¢LogEntryåˆ°PluginLogEntry
    let plugin_entries: Vec<PluginLogEntry> = entries.iter().map(|entry| {
        PluginLogEntry {
            line_number: entry.line_number,
            content: entry.content.clone(),
            timestamp: entry.timestamp.clone(),
            level: entry.level.clone(),
            formatted_content: entry.formatted_content.clone(),
            metadata: std::collections::HashMap::new(),
            processed_by: Vec::new(),
        }
    }).collect();
    
    // å¤„ç†æ—¥å¿—æ¡ç›®
    let result = plugin_manager.process_log_entries(plugin_entries).await
        .map_err(|e| format!("æ’ä»¶å¤„ç†å¤±è´¥: {}", e))?;
    
    info!("ğŸ”§ æ’ä»¶ç³»ç»Ÿå¤„ç†å®Œæˆï¼Œè¾“å‡ºæ¡ç›®æ•°: {}", result.len());
    
    // è½¬æ¢å›LogEntry
    let converted_entries: Vec<LogEntry> = result.into_iter().map(|entry| {
        LogEntry {
            line_number: entry.line_number,
            content: entry.content,
            timestamp: entry.timestamp,
            level: entry.level,
            formatted_content: entry.formatted_content,
            metadata: entry.metadata,
            processed_by: entry.processed_by,
        }
    }).collect();
    
    // è¾“å‡ºå‰å‡ ä¸ªæ¡ç›®çš„è°ƒè¯•ä¿¡æ¯
    for (i, entry) in converted_entries.iter().take(3).enumerate() {
        info!("ğŸ”§ å¤„ç†åçš„æ¡ç›® {}: è¡Œå·={}, å†…å®¹é•¿åº¦={}, formatted_content: {:?}", 
              i + 1, entry.line_number, entry.content.len(),
              entry.formatted_content.as_ref().map(|s| s.chars().take(50).collect::<String>()));
    }
    
    Ok(converted_entries)
}

// è·å–æˆ–åˆå§‹åŒ–å…¨å±€æ’ä»¶ç®¡ç†å™¨
async fn get_or_init_plugin_manager() -> Result<Arc<EnhancedPluginManager>, String> {
    if INITIALIZED.load(std::sync::atomic::Ordering::Relaxed) {
        unsafe {
            if let Some(ref manager) = PLUGIN_MANAGER {
                return Ok(manager.clone());
            }
        }
    }
    
    // åˆå§‹åŒ–æ’ä»¶ç®¡ç†å™¨
    let plugin_manager = Arc::new(EnhancedPluginManager::new());
    plugin_manager.initialize().await
        .map_err(|e| format!("æ’ä»¶ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {}", e))?;
    
    unsafe {
        PLUGIN_MANAGER = Some(plugin_manager.clone());
    }
    INITIALIZED.store(true, std::sync::atomic::Ordering::Relaxed);
    
    Ok(plugin_manager)
}

// æ£€æµ‹æ—¥å¿—æ ¼å¼
fn detect_log_format(lines: &[&str]) -> String {
    if lines.is_empty() {
        return "Unknown".to_string();
    }
    
    // æ£€æŸ¥SpringBootæ ¼å¼
    let springboot_count = lines.iter()
        .filter(|line| {
            line.contains("INFO") || line.contains("ERROR") || line.contains("WARN") || line.contains("DEBUG")
        })
        .count();
    
    if springboot_count > lines.len() / 2 {
        return "SpringBoot".to_string();
    }
    
    // æ£€æŸ¥Docker JSONæ ¼å¼
    let docker_json_count = lines.iter()
        .filter(|line| line.trim().starts_with('{') && line.contains("\"log\":") && line.contains("\"stream\":"))
        .count();
    
    if docker_json_count > lines.len() / 2 {
        return "DockerJson".to_string();
    }
    
    // æ£€æŸ¥MyBatisæ ¼å¼
    let mybatis_count = lines.iter()
        .filter(|line| line.contains("Preparing:") || line.contains("Parameters:") || line.contains("==>"))
        .count();
    
    if mybatis_count > 0 {
        return "MyBatis".to_string();
    }
    
    "Unknown".to_string()
}

// æµ‹è¯•è§£æç«¯ç‚¹
async fn test_parse(Json(request): Json<ParseRequest>) -> Result<Json<serde_json::Value>, StatusCode> {
    info!("æµ‹è¯•è§£æè¯·æ±‚: {:?}", request);
    
    // æ£€æŸ¥è¯·æ±‚ç±»å‹
    let request_type = if request.file_path.is_some() {
        "file_path"
    } else if request.content.is_some() {
        "content"
    } else {
        "unknown"
    };
    
    Ok(Json(serde_json::json!({
        "success": true,
        "message": "æµ‹è¯•æˆåŠŸ",
        "request_type": request_type,
        "request": request
    })))
}

// ä½¿ç”¨å¢å¼ºæ’ä»¶ç³»ç»Ÿå¤„ç†æ—¥å¿—

// æ—¥å¿—æ ¼å¼æšä¸¾
#[derive(Debug, PartialEq)]
enum LogFormat {
    DockerJson,
    SpringBoot,
    Generic,
}


// æ£€æµ‹æ˜¯å¦ä¸º Docker JSON æ ¼å¼è¡Œ
fn is_docker_json_line(line: &str) -> bool {
    let trimmed = line.trim();
    
    // è¯¦ç»†æ£€æµ‹æ—¥å¿—
    let starts_with_brace = trimmed.starts_with('{');
    let ends_with_brace = trimmed.ends_with('}');
    let has_log = trimmed.contains("\"log\":");
    let has_stream = trimmed.contains("\"stream\":");
    let has_time = trimmed.contains("\"time\":");
    
    info!("æ£€æµ‹ Docker JSON è¡Œ: å¼€å§‹{{={}, ç»“æŸ}}={}, log={}, stream={}, time={} | å†…å®¹: {:?}", 
         starts_with_brace, ends_with_brace, has_log, has_stream, has_time, trimmed.chars().take(200).collect::<String>());
    
    // å¿…é¡»ä»¥ { å¼€å§‹å’Œ } ç»“å°¾
    if !starts_with_brace || !ends_with_brace {
        return false;
    }
    
    // æ£€æŸ¥æ˜¯å¦åŒ…å« Docker JSON çš„å…³é”®å­—æ®µ
    has_log && has_stream && has_time
}

// æ£€æµ‹æ˜¯å¦ä¸º Spring Boot æ ¼å¼è¡Œ
fn is_spring_boot_line(line: &str) -> bool {
    // Spring Boot æ—¥å¿—é€šå¸¸åŒ…å«æ—¶é—´æˆ³å’Œæ—¥å¿—çº§åˆ«
    let has_timestamp = extract_timestamp(line).is_some();
    let has_level = extract_log_level(line).is_some();
    let has_thread = line.contains("---") && line.contains("[");
    
    // æ ‡å‡†Spring Bootæ ¼å¼
    if has_timestamp && has_level && has_thread {
        return true;
    }
    
    // æ£€æŸ¥æ˜¯å¦æ˜¯å¼‚å¸¸å †æ ˆç›¸å…³è¡Œï¼ˆè¿™äº›ä¹Ÿåº”è¯¥ç”¨Spring Bootè§£æå™¨å¤„ç†ï¼‰
    let trimmed = line.trim();
    
    // å¼‚å¸¸ç±»åè¡Œ
    if trimmed.contains("Exception:") || trimmed.contains("Error:") || 
       trimmed.ends_with("Exception") || trimmed.ends_with("Error") ||
       trimmed.starts_with("Caused by:") {
        return true;
    }
    
    // å †æ ˆè·Ÿè¸ªè¡Œ
    if trimmed.starts_with("at ") && trimmed.contains("(") && trimmed.contains(")") {
        return true;
    }
    
    false
}

// å¤„ç† Docker JSON æ ¼å¼æ—¥å¿—
fn process_docker_json_lines(lines: &[&str]) -> Vec<LogEntry> {
    let mut entries = Vec::new();
    info!("å¼€å§‹å¤„ç† Docker JSON æ ¼å¼ï¼Œæ€»è¡Œæ•°: {}", lines.len());
    
    for (index, line) in lines.iter().enumerate() {
        if let Some(parsed) = parse_docker_json_line(line) {
            info!("æˆåŠŸè§£æç¬¬ {} è¡Œ Docker JSON: level={}, stream={}, content={}", 
                 index + 1, parsed.level, parsed.stream, parsed.log_content.chars().take(50).collect::<String>());
            
            let entry = LogEntry {
                line_number: index + 1,
                content: parsed.log_content.trim().to_string(), // åªè¿”å›æ—¥å¿—å†…å®¹ï¼Œå»æ‰æ¢è¡Œç¬¦
                timestamp: Some(parsed.timestamp.clone()),
                level: Some(parsed.level.clone()),
                formatted_content: Some(parsed.log_content.trim().to_string()), // ç®€åŒ–æ ¼å¼åŒ–å†…å®¹
                metadata: std::collections::HashMap::new(),
                processed_by: vec!["docker_json_parser".to_string()],
            };
            entries.push(entry);
        } else {
            info!("ç¬¬ {} è¡Œè§£æå¤±è´¥ï¼Œä½œä¸ºæ™®é€šæ–‡æœ¬å¤„ç†: {}", 
                 index + 1, line.chars().take(100).collect::<String>());
            
            // å¦‚æœè§£æå¤±è´¥ï¼Œä½œä¸ºæ™®é€šæ–‡æœ¬å¤„ç†
            let entry = LogEntry {
                line_number: index + 1,
                content: line.to_string(),
                timestamp: extract_timestamp(line),
                level: extract_log_level(line),
                formatted_content: Some(line.trim().to_string()),
                metadata: std::collections::HashMap::new(),
                processed_by: vec!["generic_parser".to_string()],
            };
            entries.push(entry);
        }
    }
    
    info!("Docker JSON å¤„ç†å®Œæˆï¼Œç”Ÿæˆ {} ä¸ªæ¡ç›®", entries.len());
    entries
}

// Docker JSON è§£æç»“æœç»“æ„
struct DockerJsonLog {
    log_content: String,
    stream: String,
    timestamp: String,
    level: String,
}

// è§£æå•è¡Œ Docker JSON
fn parse_docker_json_line(line: &str) -> Option<DockerJsonLog> {
    use serde_json::Value;
    
    if let Ok(json) = serde_json::from_str::<Value>(line) {
        let log_content = json.get("log")?.as_str()?.to_string();
        let stream = json.get("stream")?.as_str()?.to_string();
        let timestamp = json.get("time")?.as_str()?.to_string();
        
        // æ ¹æ®æµç±»å‹å’Œå†…å®¹ç¡®å®šæ—¥å¿—çº§åˆ«
        let level = if stream == "stderr" {
            "ERROR".to_string()
        } else {
            // æ£€æŸ¥æ—¥å¿—å†…å®¹ä¸­çš„çº§åˆ«å…³é”®è¯
            let content_lower = log_content.to_lowercase();
            if content_lower.contains("error") || content_lower.contains("exception") {
                "ERROR".to_string()
            } else if content_lower.contains("warn") {
                "WARN".to_string()
            } else if content_lower.contains("debug") {
                "DEBUG".to_string()
            } else {
                "INFO".to_string()
            }
        };
        
        return Some(DockerJsonLog {
            log_content,
            stream,
            timestamp,
            level,
        });
    }
    
    None
}

// å¤„ç†é€šç”¨æ ¼å¼æ—¥å¿—
fn process_generic_lines(lines: &[&str]) -> Vec<LogEntry> {
    let mut entries = Vec::new();
    
    for (index, line) in lines.iter().enumerate() {
        let entry = LogEntry {
            line_number: index + 1,
            content: line.to_string(),
            timestamp: extract_timestamp(line),
            level: extract_log_level(line),
            formatted_content: Some(line.trim().to_string()),
            metadata: std::collections::HashMap::new(),
            processed_by: vec!["generic_parser".to_string()],
        };
        entries.push(entry);
    }
    
    entries
}

// èšåˆå¼‚å¸¸å †æ ˆè·Ÿè¸ªè¡Œ
fn aggregate_exception_lines(lines: &[&str]) -> Vec<LogEntry> {
    let mut entries = Vec::new();
    let mut i = 0;
    
    while i < lines.len() {
        let line = lines[i];
        
        // æ£€æŸ¥æ˜¯å¦æ˜¯å¼‚å¸¸å¼€å§‹è¡Œï¼ˆåŒ…å«æ—¶é—´æˆ³å’Œå¼‚å¸¸ä¿¡æ¯ï¼‰
        if is_exception_start_line(line) {
            let mut exception_content = vec![line.to_string()];
            let mut j = i + 1;
            
            // æ”¶é›†æ‰€æœ‰åç»­çš„å †æ ˆè·Ÿè¸ªè¡Œ
            while j < lines.len() && (is_stack_trace_line(lines[j]) || is_exception_continuation_line(lines[j])) {
                exception_content.push(lines[j].to_string());
                j += 1;
            }
            
            // åˆ›å»ºèšåˆçš„å¼‚å¸¸æ¡ç›®
            let full_content = exception_content.join("\n");
            let entry = LogEntry {
                line_number: i + 1,
                content: full_content,
                timestamp: extract_timestamp(line),
                level: extract_log_level(line),
                formatted_content: Some(exception_content.join("\n")),
                metadata: std::collections::HashMap::new(),
                processed_by: vec!["exception_aggregator".to_string()],
            };
            entries.push(entry);
            
            // è·³è¿‡å·²å¤„ç†çš„è¡Œ
            i = j;
        } else {
            // æ™®é€šæ—¥å¿—è¡Œ
            let entry = LogEntry {
                line_number: i + 1,
                content: line.to_string(),
                timestamp: extract_timestamp(line),
                level: extract_log_level(line),
                formatted_content: Some(line.trim().to_string()),
                metadata: std::collections::HashMap::new(),
                processed_by: vec!["generic_parser".to_string()],
            };
            entries.push(entry);
            i += 1;
        }
    }
    
    entries
}

// æ£€æŸ¥æ˜¯å¦æ˜¯å¼‚å¸¸å¼€å§‹è¡Œ
fn is_exception_start_line(line: &str) -> bool {
    let has_timestamp = extract_timestamp(line).is_some();
    let has_error_level = extract_log_level(line) == Some("ERROR".to_string());
    
    // æƒ…å†µ1ï¼šæ ‡å‡†æ—¥å¿—è¡Œ + ERRORçº§åˆ«ï¼ˆå¼‚å¸¸çš„æ­£å¼å¼€å§‹ï¼‰
    if has_timestamp && has_error_level {
        return true;
    }
    
    // æƒ…å†µ2ï¼šç›´æ¥çš„å¼‚å¸¸ç±»åè¡Œï¼ˆç´§æ¥åœ¨ERRORæ—¥å¿—åï¼‰
    let trimmed = line.trim();
    if !has_timestamp && (
        trimmed.contains("Exception:") || 
        trimmed.contains("Error:") ||
        trimmed.ends_with("Exception") ||
        trimmed.ends_with("Error") ||
        trimmed.starts_with("Caused by:")
    ) {
        return true;
    }
    
    false
}

// æ£€æŸ¥æ˜¯å¦æ˜¯å †æ ˆè·Ÿè¸ªè¡Œ
fn is_stack_trace_line(line: &str) -> bool {
    let trimmed = line.trim();
    
    // æ ‡å‡†Javaå †æ ˆè·Ÿè¸ªæ ¼å¼
    if trimmed.starts_with("at ") {
        return true;
    }
    
    // Caused by è¡Œ
    if trimmed.starts_with("Caused by:") {
        return true;
    }
    
    // Suppressed è¡Œ
    if trimmed.starts_with("Suppressed:") {
        return true;
    }
    
    // common frames omitted
    if trimmed.contains("common frames omitted") || trimmed.contains("more") {
        return true;
    }
    
    false
}

// æ£€æŸ¥æ˜¯å¦æ˜¯å¼‚å¸¸ç»§ç»­è¡Œ
fn is_exception_continuation_line(line: &str) -> bool {
    let trimmed = line.trim();
    
    if trimmed.is_empty() {
        return false;
    }
    
    // æ²¡æœ‰æ—¶é—´æˆ³çš„éå †æ ˆè·Ÿè¸ªè¡Œï¼Œå¯èƒ½æ˜¯å¼‚å¸¸æ¶ˆæ¯
    if !extract_timestamp(line).is_some() && !trimmed.starts_with("at ") {
        // æ£€æŸ¥æ˜¯å¦æ˜¯ä¸‹ä¸€ä¸ªæ­£å¸¸æ—¥å¿—çš„å¼€å§‹
        // å¦‚æœåŒ…å«æ—¥å¿—çº§åˆ«å…³é”®è¯ï¼Œåˆ™ä¸æ˜¯å¼‚å¸¸ç»§ç»­è¡Œ
        let level_keywords = ["INFO", "DEBUG", "WARN", "ERROR", "TRACE"];
        let has_level_keyword = level_keywords.iter().any(|keyword| line.contains(keyword));
        
        if !has_level_keyword {
            return true;
        }
    }
    
    false
}

// æå–æ—¶é—´æˆ³
fn extract_timestamp(line: &str) -> Option<String> {
    use regex::Regex;
    
    // å¸¸è§çš„æ—¶é—´æˆ³æ ¼å¼
    let patterns = vec![
        r"\d{4}-\d{2}-\d{2}[\s\T]\d{2}:\d{2}:\d{2}",
        r"\d{2}/\d{2}/\d{4}\s+\d{2}:\d{2}:\d{2}",
        r"\d{2}-\d{2}-\d{4}\s+\d{2}:\d{2}:\d{2}",
    ];
    
    for pattern in patterns {
        if let Ok(re) = Regex::new(pattern) {
            if let Some(captures) = re.find(line) {
                return Some(captures.as_str().to_string());
            }
        }
    }
    
    None
}

// æå–æ—¥å¿—çº§åˆ«
fn extract_log_level(line: &str) -> Option<String> {
    let line_lower = line.to_lowercase();
    
    if line_lower.contains("error") || line_lower.contains("err") {
        Some("ERROR".to_string())
    } else if line_lower.contains("warn") || line_lower.contains("warning") {
        Some("WARN".to_string())
    } else if line_lower.contains("info") {
        Some("INFO".to_string())
    } else if line_lower.contains("debug") {
        Some("DEBUG".to_string())
    } else if line_lower.contains("trace") {
        Some("TRACE".to_string())
    } else {
        Some("INFO".to_string()) // é»˜è®¤çº§åˆ«
    }
}

// é…ç½®ç›¸å…³APIå¤„ç†å‡½æ•°
async fn get_theme_config(
    State(config_service): State<Arc<ConfigService>>
) -> Result<Json<ConfigResponse>, StatusCode> {
    match config_service.get_theme_config().await {
        Ok(theme) => {
            let response = ThemeResponse {
                mode: match theme.mode {
                    ThemeMode::Light => "light".to_string(),
                    ThemeMode::Dark => "dark".to_string(),
                    ThemeMode::Auto => "auto".to_string(),
                },
                primary_color: theme.primary_color,
                accent_color: theme.accent_color,
                font_size: theme.font_size,
                font_family: theme.font_family,
            };
            
            Ok(Json(ConfigResponse {
                success: true,
                message: "ä¸»é¢˜é…ç½®è·å–æˆåŠŸ".to_string(),
                data: Some(serde_json::to_value(response).unwrap()),
            }))
        }
        Err(e) => {
            log::error!("è·å–ä¸»é¢˜é…ç½®å¤±è´¥: {}", e);
            Err(StatusCode::INTERNAL_SERVER_ERROR)
        }
    }
}

async fn update_theme_config(
    State(config_service): State<Arc<ConfigService>>,
    Json(request): Json<ThemeUpdateRequest>
) -> Result<Json<ConfigResponse>, StatusCode> {
    // è·å–å½“å‰é…ç½®
    let mut theme = match config_service.get_theme_config().await {
        Ok(theme) => theme,
        Err(e) => {
            log::error!("è·å–å½“å‰ä¸»é¢˜é…ç½®å¤±è´¥: {}", e);
            return Err(StatusCode::INTERNAL_SERVER_ERROR);
        }
    };

    // æ›´æ–°é…ç½®
    theme.mode = match request.mode.as_str() {
        "light" => ThemeMode::Light,
        "dark" => ThemeMode::Dark,
        "auto" => ThemeMode::Auto,
        _ => ThemeMode::Auto,
    };

    if let Some(primary_color) = request.primary_color {
        theme.primary_color = primary_color;
    }
    if let Some(accent_color) = request.accent_color {
        theme.accent_color = accent_color;
    }
    if let Some(font_size) = request.font_size {
        theme.font_size = font_size;
    }
    if let Some(font_family) = request.font_family {
        theme.font_family = font_family;
    }

    match config_service.set_theme_config(&theme).await {
        Ok(_) => Ok(Json(ConfigResponse {
            success: true,
            message: "ä¸»é¢˜é…ç½®æ›´æ–°æˆåŠŸ".to_string(),
            data: None,
        })),
        Err(e) => {
            log::error!("æ›´æ–°ä¸»é¢˜é…ç½®å¤±è´¥: {}", e);
            Err(StatusCode::INTERNAL_SERVER_ERROR)
        }
    }
}

async fn get_parse_config(
    State(config_service): State<Arc<ConfigService>>
) -> Result<Json<ConfigResponse>, StatusCode> {
    match config_service.get_parse_config().await {
        Ok(parse) => {
            let data = serde_json::json!({
                "auto_parse": parse.auto_parse,
                "show_line_numbers": parse.show_line_numbers,
                "max_file_size": parse.max_file_size,
                "chunk_size": parse.chunk_size,
                "timeout_seconds": parse.timeout_seconds,
            });
            
            Ok(Json(ConfigResponse {
                success: true,
                message: "è§£æé…ç½®è·å–æˆåŠŸ".to_string(),
                data: Some(data),
            }))
        }
        Err(e) => {
            log::error!("è·å–è§£æé…ç½®å¤±è´¥: {}", e);
            Err(StatusCode::INTERNAL_SERVER_ERROR)
        }
    }
}

async fn get_plugin_config(
    State(config_service): State<Arc<ConfigService>>
) -> Result<Json<ConfigResponse>, StatusCode> {
    match config_service.get_plugin_config().await {
        Ok(plugin) => {
            let data = serde_json::json!({
                "auto_update": plugin.auto_update,
                "enable_notifications": plugin.enable_notifications,
                "plugin_directory": plugin.plugin_directory,
                "max_plugins": plugin.max_plugins,
            });
            
            Ok(Json(ConfigResponse {
                success: true,
                message: "æ’ä»¶é…ç½®è·å–æˆåŠŸ".to_string(),
                data: Some(data),
            }))
        }
        Err(e) => {
            log::error!("è·å–æ’ä»¶é…ç½®å¤±è´¥: {}", e);
            Err(StatusCode::INTERNAL_SERVER_ERROR)
        }
    }
}

async fn get_window_config(
    State(config_service): State<Arc<ConfigService>>
) -> Result<Json<ConfigResponse>, StatusCode> {
    match config_service.get_window_config().await {
        Ok(window) => {
            let data = serde_json::json!({
                "width": window.width,
                "height": window.height,
                "maximized": window.maximized,
                "always_on_top": window.always_on_top,
                "remember_position": window.remember_position,
            });
            
            Ok(Json(ConfigResponse {
                success: true,
                message: "çª—å£é…ç½®è·å–æˆåŠŸ".to_string(),
                data: Some(data),
            }))
        }
        Err(e) => {
            log::error!("è·å–çª—å£é…ç½®å¤±è´¥: {}", e);
            Err(StatusCode::INTERNAL_SERVER_ERROR)
        }
    }
}

async fn get_all_configs(
    State(config_service): State<Arc<ConfigService>>
) -> Result<Json<ConfigResponse>, StatusCode> {
    match config_service.get_all_configs().await {
        Ok(configs) => {
            let data = serde_json::to_value(configs).unwrap();
            
            Ok(Json(ConfigResponse {
                success: true,
                message: "æ‰€æœ‰é…ç½®è·å–æˆåŠŸ".to_string(),
                data: Some(data),
            }))
        }
        Err(e) => {
            log::error!("è·å–æ‰€æœ‰é…ç½®å¤±è´¥: {}", e);
            Err(StatusCode::INTERNAL_SERVER_ERROR)
        }
    }
}

// åŠ è½½é…ç½®
fn load_config() -> AppConfig {
    // ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶åŠ è½½
    let port = env::var("LOGWHISPER_PORT")
        .ok()
        .and_then(|s| s.parse().ok())
        .unwrap_or(3030);
    
    let log_file = env::var("LOGWHISPER_LOG_FILE")
        .unwrap_or_else(|_| "logs/log-whisper.log".to_string());
    
    let log_level = env::var("LOGWHISPER_LOG_LEVEL")
        .unwrap_or_else(|_| "info".to_string());
    
    AppConfig {
        port,
        log_file,
        log_level,
    }
}

// åˆå§‹åŒ–æ—¥å¿—
fn init_logger(config: &AppConfig) -> Result<(), Box<dyn std::error::Error>> {
    // ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
    if let Some(log_dir) = Path::new(&config.log_file).parent() {
        fs::create_dir_all(log_dir)?;
    }
    
    // è®¾ç½®æ—¥å¿—çº§åˆ«
    let log_level = match config.log_level.to_lowercase().as_str() {
        "trace" => log::LevelFilter::Trace,
        "debug" => log::LevelFilter::Debug,
        "info" => log::LevelFilter::Info,
        "warn" => log::LevelFilter::Warn,
        "error" => log::LevelFilter::Error,
        _ => log::LevelFilter::Info,
    };
    
    // åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
    env_logger::Builder::from_default_env()
        .filter_level(log_level)
        .target(env_logger::Target::Stdout)
        .init();
    
    info!("æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ");
    info!("æ—¥å¿—çº§åˆ«: {}", config.log_level);
    info!("æ—¥å¿—æ–‡ä»¶: {}", config.log_file);
    
    Ok(())
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // åŠ è½½é…ç½®
    let config = load_config();
    
    // åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
    init_logger(&config)?;
    
    info!("ğŸš€ LogWhisper API æœåŠ¡å™¨å¯åŠ¨ä¸­...");
    info!("ğŸ“‹ é…ç½®ä¿¡æ¯:");
    info!("  - ç«¯å£: {}", config.port);
    info!("  - æ—¥å¿—æ–‡ä»¶: {}", config.log_file);
    info!("  - æ—¥å¿—çº§åˆ«: {}", config.log_level);
    
    // åˆå§‹åŒ–é…ç½®æœåŠ¡
    let config_service = Arc::new(ConfigService::new("./config.db").map_err(|e| format!("é…ç½®æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {}", e))?);
    info!("âœ… é…ç½®æœåŠ¡åˆå§‹åŒ–å®Œæˆ");
    
    // åˆå§‹åŒ–æ’ä»¶ç³»ç»Ÿ
    let plugin_manager = Arc::new(EnhancedPluginManager::new());
    plugin_manager.initialize().await.map_err(|e| format!("æ’ä»¶ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {}", e))?;
    info!("âœ… æ’ä»¶ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ");
    
    // åˆ›å»º CORS å±‚
    let cors = CorsLayer::new()
        .allow_origin(tower_http::cors::Any)
        .allow_methods(tower_http::cors::Any)
        .allow_headers(tower_http::cors::Any);
    
    // æ„å»ºè·¯ç”±
    let app = Router::new()
        .route("/health", get(health_check))
        .route("/api/plugins", get(get_plugins))
        .route("/api/parse", post(parse_log))
        .route("/api/test", post(test_parse))
        // é…ç½®ç›¸å…³è·¯ç”±
        .route("/api/config/theme", get(get_theme_config))
        .route("/api/config/theme", post(update_theme_config))
        .route("/api/config/parse", get(get_parse_config))
        .route("/api/config/plugin", get(get_plugin_config))
        .route("/api/config/window", get(get_window_config))
        .route("/api/config/all", get(get_all_configs))
        .with_state(config_service)
        .layer(cors);
    
    // å¯åŠ¨æœåŠ¡å™¨
    let addr = format!("127.0.0.1:{}", config.port);
    
    info!("ğŸŒ API æœåŠ¡å™¨å¯åŠ¨åœ¨: http://{}", addr);
    info!("ğŸ“‹ API ç«¯ç‚¹:");
    info!("  - GET  /health");
    info!("  - GET  /api/plugins");
    info!("  - POST /api/parse");
    info!("  - GET  /api/config/theme");
    info!("  - POST /api/config/theme");
    info!("  - GET  /api/config/parse");
    info!("  - GET  /api/config/plugin");
    info!("  - GET  /api/config/window");
    info!("  - GET  /api/config/all");
    
    let listener = tokio::net::TcpListener::bind(&addr).await?;
    axum::serve(listener, app).await?;
    
    Ok(())
}